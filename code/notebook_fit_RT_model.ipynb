{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Bayesian Linear Regression using PyStan\n",
    "**Florian Ott, 2021**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we fit response times against conflict, also checking for a context interaction. Further description of the analysis and visualization of the results can be found in the main manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import pystan\n",
    "import glob as glob \n",
    "import time as time\n",
    "import arviz as az\n",
    "plt.style.use('ara')\n",
    "\n",
    "# Load participant data\n",
    "filename = glob.glob('../data/behaviour/data_all_participants_20220215120148.csv') \n",
    "dat = pd.read_csv(filename[0],index_col = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = '''\n",
    "data {\n",
    "  int<lower=1> N;\n",
    "  vector[N] ishard;\n",
    "  vector[N] logrt;\n",
    "  vector[N] conflict;\n",
    "  int<lower=1> N_subjects;\n",
    "  int<lower = 1, upper = N> vpn[N];\n",
    "  int<lower=1> N_rep;\n",
    "  vector[N_rep] conflict_rep;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  // hyperparameters\n",
    "  real mu_intercept;\n",
    "  real mu_beta_conflict;\n",
    "  real mu_beta_ishard;\n",
    "  real mu_beta_interaction;\n",
    "  real<lower=0> sigma_intercept;\n",
    "  real<lower=0> sigma_beta_conflict;\n",
    "  real<lower=0> sigma_ishard;\n",
    "  real<lower=0> sigma_interaction;\n",
    "  \n",
    "  // paramters \n",
    "  vector[N_subjects] intercept;\n",
    "  vector[N_subjects] beta_conflict;\n",
    "  vector[N_subjects] beta_ishard;\n",
    "  vector[N_subjects] beta_interaction; \n",
    "  real<lower=0>  sigma; //same data level noise for all subjects \n",
    "  \n",
    "}\n",
    "\n",
    "model {\n",
    "\n",
    "  // hyper priors \n",
    "  mu_intercept ~ normal(0,10); \n",
    "  mu_beta_conflict ~ normal(0,10); \n",
    "  mu_beta_ishard ~ normal(0,10); \n",
    "  mu_beta_interaction ~ normal(0,10); \n",
    "  sigma_intercept ~ normal(0,10); \n",
    "  sigma_beta_conflict ~ normal(0,10); \n",
    "  sigma_ishard ~ normal(0,10); \n",
    "  sigma_interaction ~ normal(0,10); \n",
    "\n",
    "  \n",
    "  //priors \n",
    "  intercept ~ normal(mu_intercept,sigma_intercept); \n",
    "  beta_conflict ~ normal(mu_beta_conflict,sigma_beta_conflict); \n",
    "  beta_ishard ~ normal(mu_beta_ishard,sigma_ishard); \n",
    "  beta_interaction ~ normal(mu_beta_interaction,sigma_interaction);\n",
    "  sigma ~ normal(0, 10);\n",
    "\n",
    "  logrt ~ normal(intercept[vpn] + beta_conflict[vpn].*conflict + beta_ishard[vpn].*ishard + beta_interaction[vpn] .* conflict .* ishard,sigma);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "\n",
    "  vector[N_subjects] intercept_rep;\n",
    "  vector[N_subjects] beta_conflict_rep;\n",
    "  vector[N_subjects] beta_ishard_rep;\n",
    "  vector[N_subjects] beta_interaction_rep;\n",
    "  vector[N_rep] rt_new_easy;\n",
    "  vector[N_rep] rt_new_hard;\n",
    "  \n",
    "  for (n in 1:N_subjects){\n",
    "    intercept_rep[n] = normal_rng(intercept[n], sigma_intercept);\n",
    "    beta_conflict_rep[n] = normal_rng(beta_conflict[n], sigma_beta_conflict);\n",
    "    beta_ishard_rep[n] = normal_rng(beta_ishard[n], sigma_ishard);\n",
    "    beta_interaction_rep[n] = normal_rng(beta_interaction[n], sigma_interaction);\n",
    "    }\n",
    "\n",
    "  for (n in 1:N_rep){\n",
    "    rt_new_easy[n] = lognormal_rng(intercept_rep[vpn[n]] + conflict_rep[n] * beta_conflict_rep[vpn[n]] + beta_ishard_rep[vpn[n]]*0 + beta_interaction_rep[vpn[n]] * conflict_rep[n] * 0 ,sigma);\n",
    "    rt_new_hard[n] = lognormal_rng(intercept_rep[vpn[n]] + conflict_rep[n] * beta_conflict_rep[vpn[n]] + beta_ishard_rep[vpn[n]]*1 + beta_interaction_rep[vpn[n]] * conflict_rep[n] * 1 ,sigma);\n",
    "    } \n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_1989a5f201a87f58e7e2e78ff7aa273a NOW.\n"
     ]
    }
   ],
   "source": [
    "sm = pystan.StanModel(model_code=model,verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (dat['timeout'] == 0)\n",
    "logrt =  np.log(dat.loc[idx,['reaction_time']].to_numpy().squeeze())\n",
    "conflict = dat.loc[idx,['conflict_planning']].to_numpy().squeeze()\n",
    "ishard = dat.loc[idx,['is_23']].to_numpy(dtype='int').squeeze()\n",
    "N = len(logrt)\n",
    "vpn = dat.loc[idx,['vpn']].to_numpy().squeeze() - 100\n",
    "N_subjects = len(np.unique(vpn))\n",
    "conflict_rep = conflict\n",
    "N_rep = len(conflict_rep)\n",
    "\n",
    "dat_dict = {'N':N,         \n",
    "            'logrt':logrt,\n",
    "            'conflict':conflict, \n",
    "            'ishard':ishard ,\n",
    "            'N_subjects':N_subjects,\n",
    "            'vpn':vpn,\n",
    "            'N_rep':N_rep,\n",
    "            'conflict_rep':conflict_rep           \n",
    "            } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling posterior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    }
   ],
   "source": [
    "res = sm.sampling(data=dat_dict, iter=2000,  warmup=1000, thin=1, chains=4,control=dict(adapt_delta=0.97),seed=101, verbose = False);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
