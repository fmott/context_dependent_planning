{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model recovery analysis\n",
    "#### Florian Ott, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we test the range of parameter values for which the hybrid model (*HM (I)P+S (E)P+S 2beta*) is distinguishable from the planning model (*PM (I)P (E)P*) and the simple model (*SM (I)S (E)S*). Note that we used a non-hierarchical version of the HM, PM and SM, which allows us to demonstrate model distinguishability at moderate computational expense. Please refer to the manuscript for further explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pystan\n",
    "import arviz as az\n",
    "import glob as glob\n",
    "import time as time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import pickle\n",
    "plt.style.use('ara')\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "## Load particpant data \n",
    "filename = glob.glob('../data/behaviour/data_all_participants_20220215120148.csv') \n",
    "dat = pd.read_csv(filename[0],index_col = 0)\n",
    "\n",
    "## Load model data\n",
    "# Posterior mean and credibility intervals of estimated parameters\n",
    "with open(\"../data/model/summary_HM_20220216143030.pkl\", \"rb\") as f:\n",
    "    summary_hybrid = pickle.load(f)['summary']\n",
    "\n",
    "idx = dat['timeout'] == 0\n",
    "dat_subset = dat.loc[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stan code for the flat version of the PM\n",
    "flat_m1 = '''\n",
    "data {\n",
    "  int<lower=0> N;\n",
    "  int<lower=0,upper=1> response[N];\n",
    "  vector[N] dv;\n",
    "  vector[N] is_basic;\n",
    "  vector[N] is_full_energy;\n",
    "  vector[N] is_low_energy_LC;\n",
    "  vector[N] is_low_energy_HC;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real theta_basic;\n",
    "  real theta_full_energy;\n",
    "  real theta_low_energy_LC;\n",
    "  real theta_low_energy_HC;\n",
    "  real beta_dv;\n",
    "}\n",
    "\n",
    "model {\n",
    "  theta_basic ~ normal(0, 2);\n",
    "  theta_full_energy ~ normal(0, 2);\n",
    "  theta_low_energy_LC ~ normal(0, 2);\n",
    "  theta_low_energy_HC ~ normal(0, 2);\n",
    "  beta_dv ~ normal(0, 2);  \n",
    "\n",
    "  response ~ bernoulli_logit(theta_full_energy * is_full_energy + theta_low_energy_LC * is_low_energy_LC + theta_low_energy_HC * is_low_energy_HC + theta_basic * is_basic + beta_dv * dv);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "  vector[N] log_lik;\n",
    "  vector[N] response_new;\n",
    "\n",
    "// pointwise log-likelihood\n",
    "  for (n in 1:N) {\n",
    "    log_lik[n] = bernoulli_logit_lpmf(response[n]  |  (theta_full_energy * is_full_energy[n] + theta_low_energy_LC * is_low_energy_LC[n] + theta_low_energy_HC * is_low_energy_HC[n] + theta_basic * is_basic[n] + beta_dv * dv[n]));\n",
    "    }\n",
    "\n",
    "// posterior predictive simulation  \n",
    "\n",
    "  for (n in 1:N){\n",
    "    response_new[n] = bernoulli_logit_rng(theta_full_energy * is_full_energy[n] + theta_low_energy_LC * is_low_energy_LC[n] + theta_low_energy_HC * is_low_energy_HC[n] + theta_basic * is_basic[n] + beta_dv * dv[n]);\n",
    "    } \n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stan code for the flat version of the HM model\n",
    "flat_m2 = '''\n",
    "data {\n",
    "  int<lower=0> N;\n",
    "  int<lower=0,upper=1> response[N];\n",
    "  vector[N] dv;\n",
    "  vector[N] is_basic_1;\n",
    "  vector[N] is_basic_2;\n",
    "  vector[N] is_basic_3;\n",
    "  vector[N] is_basic_4;\n",
    "  vector[N] is_23;\n",
    "  vector[N] is_14;\n",
    "  vector[N] is_full_energy;\n",
    "  vector[N] is_low_energy_LC;\n",
    "  vector[N] is_low_energy_HC;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real theta_basic_1;\n",
    "  real theta_basic_2;\n",
    "  real theta_basic_3;\n",
    "  real theta_basic_4;\n",
    "  real theta_full_energy;\n",
    "  real theta_low_energy_LC;\n",
    "  real theta_low_energy_HC;\n",
    "  real beta_dv_23;\n",
    "  real beta_dv_14;\n",
    "\n",
    "}\n",
    "\n",
    "model {\n",
    "// priors\n",
    "  theta_basic_1 ~ normal(0,2);\n",
    "  theta_basic_2 ~ normal(0,2);\n",
    "  theta_basic_3 ~ normal(0,2);\n",
    "  theta_basic_4 ~ normal(0,2);\n",
    "  theta_full_energy ~ normal(0,2);\n",
    "  theta_low_energy_LC ~ normal(0,2);\n",
    "  theta_low_energy_HC ~ normal(0,2);\n",
    "  beta_dv_23 ~ normal(0,2);  \n",
    "  beta_dv_14 ~ normal(0,2);  \n",
    "\n",
    "\n",
    "// likelihood \n",
    "  response ~ bernoulli_logit(theta_full_energy * is_full_energy + theta_low_energy_LC * is_low_energy_LC + theta_low_energy_HC * is_low_energy_HC + theta_basic_1 * is_basic_1 + theta_basic_2 * is_basic_2 + theta_basic_3 * is_basic_3 + theta_basic_4 * is_basic_4 + beta_dv_23 * dv .* is_23 + beta_dv_14 * dv .* is_14);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "  vector[N] log_lik;\n",
    "  vector[N] response_new;\n",
    "\n",
    "// pointwise log-likelihood\n",
    "  for (n in 1:N) {\n",
    "    log_lik[n] = bernoulli_logit_lpmf(response[n]  |  (theta_full_energy * is_full_energy[n] + theta_low_energy_LC * is_low_energy_LC[n] + theta_low_energy_HC * is_low_energy_HC[n] + theta_basic_1  * is_basic_1[n] + theta_basic_2  * is_basic_2[n] + theta_basic_3  * is_basic_3[n] + theta_basic_4 * is_basic_4[n] + beta_dv_23 * dv[n] * is_23[n] + beta_dv_14 * dv[n] * is_14[n] ));\n",
    "    }\n",
    "\n",
    "// posterior predictive simulation  \n",
    "\n",
    "  for (n in 1:N){\n",
    "    response_new[n] = bernoulli_logit_rng(theta_full_energy * is_full_energy[n] + theta_low_energy_LC * is_low_energy_LC[n] + theta_low_energy_HC * is_low_energy_HC[n] + theta_basic_1  * is_basic_1[n] + theta_basic_2  * is_basic_2[n] + theta_basic_3 * is_basic_3[n] + theta_basic_4 * is_basic_4[n] + beta_dv_23  * dv[n] * is_23[n] + beta_dv_14  * dv[n] * is_14[n] );\n",
    "    } \n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stan code for the flat version of the SM model\n",
    "flat_m3 = '''\n",
    "data {\n",
    "  int<lower=0> N;\n",
    "  int<lower=0,upper=1> response[N];\n",
    "  vector[N] is_basic_1;\n",
    "  vector[N] is_basic_2;\n",
    "  vector[N] is_basic_3;\n",
    "  vector[N] is_basic_4;\n",
    "  vector[N] is_full_energy;\n",
    "  vector[N] is_low_energy_LC;\n",
    "  vector[N] is_low_energy_HC;\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real theta_basic_1;\n",
    "  real theta_basic_2;\n",
    "  real theta_basic_3;\n",
    "  real theta_basic_4;\n",
    "  real theta_full_energy;\n",
    "  real theta_low_energy_LC;\n",
    "  real theta_low_energy_HC;\n",
    "}\n",
    "\n",
    "model {\n",
    "// priors\n",
    "  theta_basic_1 ~ normal(0,2);\n",
    "  theta_basic_2 ~ normal(0,2);\n",
    "  theta_basic_3 ~ normal(0,2);\n",
    "  theta_basic_4 ~ normal(0,2);\n",
    "  theta_full_energy ~ normal(0,2);\n",
    "  theta_low_energy_LC ~ normal(0,2);\n",
    "  theta_low_energy_HC ~ normal(0,2);\n",
    "\n",
    "// likelihood \n",
    "  response ~ bernoulli_logit(theta_full_energy * is_full_energy + theta_low_energy_LC * is_low_energy_LC + theta_low_energy_HC * is_low_energy_HC + theta_basic_1 * is_basic_1 + theta_basic_2 * is_basic_2 + theta_basic_3 * is_basic_3 + theta_basic_4 * is_basic_4);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "  vector[N] log_lik;\n",
    "  vector[N] response_new;\n",
    "\n",
    "// pointwise log-likelihood\n",
    "  for (n in 1:N) {\n",
    "    log_lik[n] = bernoulli_logit_lpmf(response[n]  |  (theta_full_energy * is_full_energy[n] + theta_low_energy_LC * is_low_energy_LC[n] + theta_low_energy_HC * is_low_energy_HC[n] + theta_basic_1  * is_basic_1[n] + theta_basic_2  * is_basic_2[n] + theta_basic_3  * is_basic_3[n] + theta_basic_4 * is_basic_4[n] ));\n",
    "    }\n",
    "\n",
    "// posterior predictive simulation  \n",
    "\n",
    "  for (n in 1:N){\n",
    "    response_new[n] = bernoulli_logit_rng(theta_full_energy * is_full_energy[n] + theta_low_energy_LC * is_low_energy_LC[n] + theta_low_energy_HC * is_low_energy_HC[n] + theta_basic_1  * is_basic_1[n] + theta_basic_2  * is_basic_2[n] + theta_basic_3 * is_basic_3[n] + theta_basic_4 * is_basic_4[n]);\n",
    "    } \n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_a3f6ea7031342da4236663488ef0aea9 NOW.\n"
     ]
    }
   ],
   "source": [
    "sm_flat_m1 = pystan.StanModel(model_code=flat_m1,verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_4424221ebd75a70e372f5027b9ef5bae NOW.\n"
     ]
    }
   ],
   "source": [
    "sm_flat_m2 = pystan.StanModel(model_code=flat_m2,verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_f3cfc8e7fc0c4c06d40a9a06aed64a27 NOW.\n"
     ]
    }
   ],
   "source": [
    "sm_flat_m3 = pystan.StanModel(model_code=flat_m3,verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vary preference parameters $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate novel responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simulate novel data for refitting \n",
    "is_full_energy_rep = dat['is_full_energy'].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_LC_rep = dat['is_low_energy_LC'].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_HC_rep = dat['is_low_energy_HC'].to_numpy(dtype='int').squeeze()\n",
    "is_basic_1_rep = dat['is_basic_1'].to_numpy(dtype='int').squeeze()\n",
    "is_basic_2_rep = dat['is_basic_2'].to_numpy(dtype='int').squeeze()\n",
    "is_basic_3_rep = dat['is_basic_3'].to_numpy(dtype='int').squeeze()\n",
    "is_basic_4_rep = dat['is_basic_4'].to_numpy(dtype='int').squeeze()\n",
    "is_basic_rep = dat['is_basic'].to_numpy(dtype='int').squeeze()\n",
    "is_23_rep = dat['is_23'].to_numpy(dtype='int').squeeze()\n",
    "is_14_rep = dat['is_14'].to_numpy(dtype='int').squeeze()\n",
    "dv_rep = dat['dv_planning'].to_numpy().squeeze()\n",
    "\n",
    "# Get posterior mean of group parameters and set range of parameters of interest\n",
    "beta_dv_23_rep = summary_hybrid['mu_beta_dv_23']['mean'].to_numpy()\n",
    "beta_dv_14_rep = summary_hybrid['mu_beta_dv_14']['mean'].to_numpy()\n",
    "theta_basic_1_rep = np.arange(0,-6,-1)\n",
    "theta_basic_2_rep = np.arange(0,-6,-1)\n",
    "theta_basic_3_rep = np.arange(0,6)\n",
    "theta_basic_4_rep = np.arange(0,6)\n",
    "theta_full_energy_rep = summary_hybrid['theta_full_energy']['mean'].to_numpy()\n",
    "theta_low_energy_HC_rep = summary_hybrid['theta_low_energy_HC']['mean'].to_numpy()\n",
    "theta_low_energy_LC_rep = summary_hybrid['theta_low_energy_LC']['mean'].to_numpy()\n",
    "\n",
    "# Sample novel binary responses\n",
    "n_param_combinations = 6\n",
    "response_rep = np.zeros((len(dat),n_param_combinations))\n",
    "for i in range(n_param_combinations):\n",
    "    logits_rep = theta_full_energy_rep * is_full_energy_rep + theta_low_energy_LC_rep * is_low_energy_LC_rep + theta_low_energy_HC_rep * is_low_energy_HC_rep + theta_basic_1_rep[i] * is_basic_1_rep + theta_basic_2_rep[i] * is_basic_2_rep + theta_basic_3_rep[i] * is_basic_3_rep + theta_basic_4_rep[i] * is_basic_4_rep + beta_dv_23_rep * dv_rep * is_23_rep + beta_dv_14_rep * dv_rep * is_14_rep\n",
    "    p_rep = sigmoid(logits_rep) \n",
    "    response_rep[:,i] = stats.bernoulli.rvs(p_rep)\n",
    "response_rep = np.array(response_rep,dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the data and sampling posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    }
   ],
   "source": [
    "control_dict = dict(adapt_delta=0.95)\n",
    "idx = (dat['timeout'] == 0)\n",
    "is_full_energy = dat.loc[idx,['is_full_energy']].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_LC = dat.loc[idx,['is_low_energy_LC']].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_HC = dat.loc[idx,['is_low_energy_HC']].to_numpy(dtype='int').squeeze()\n",
    "is_basic = dat.loc[idx,['is_basic']].to_numpy(dtype='int').squeeze()\n",
    "dv = dat.loc[idx,['dv_planning']].to_numpy().squeeze()\n",
    "\n",
    "looic_planning_i_vary_theta = np.zeros(n_param_combinations)\n",
    "looic_planning_se_i_vary_theta = np.zeros(n_param_combinations)\n",
    "for i in range(n_param_combinations):\n",
    "    dat_dict_planning = {'N':len(dv),         \n",
    "                'response':response_rep[idx,i],\n",
    "                'dv':dv, \n",
    "                'is_full_energy':is_full_energy ,\n",
    "                'is_low_energy_LC':is_low_energy_LC,\n",
    "                'is_low_energy_HC':is_low_energy_HC,\n",
    "                'is_basic':is_basic\n",
    "                } \n",
    "\n",
    "\n",
    "    res_planning = sm_flat_m1.sampling(data=dat_dict_planning, iter=2000,  warmup=1000, thin=1, chains=4,seed=101, verbose = False);\n",
    "    idata_planning = az.from_pystan(posterior=res_planning,log_likelihood='log_lik')\n",
    "    looic_planning = az.loo(idata_planning,pointwise=True,scale='deviance')\n",
    "    looic_planning_i_vary_theta[i]=looic_planning[0]\n",
    "    looic_planning_se_i_vary_theta[i]=looic_planning[1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    }
   ],
   "source": [
    "control_dict = dict(adapt_delta=0.95)\n",
    "idx = (dat['timeout'] == 0)\n",
    "is_full_energy = dat.loc[idx,['is_full_energy']].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_LC = dat.loc[idx,['is_low_energy_LC']].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_HC = dat.loc[idx,['is_low_energy_HC']].to_numpy(dtype='int').squeeze()\n",
    "is_basic_1 = dat.loc[idx,['is_basic_1']].to_numpy(dtype='int').squeeze()\n",
    "is_basic_2 = dat.loc[idx,['is_basic_2']].to_numpy(dtype='int').squeeze()\n",
    "is_basic_3 = dat.loc[idx,['is_basic_3']].to_numpy(dtype='int').squeeze()\n",
    "is_basic_4 = dat.loc[idx,['is_basic_4']].to_numpy(dtype='int').squeeze()\n",
    "is_basic = dat.loc[idx,['is_basic']].to_numpy(dtype='int').squeeze()\n",
    "is_23 = dat.loc[idx,['is_23']].to_numpy(dtype='int').squeeze()\n",
    "is_14 = dat.loc[idx,['is_14']].to_numpy(dtype='int').squeeze()\n",
    "dv = dat.loc[idx,['dv_planning']].to_numpy().squeeze()\n",
    "\n",
    "looic_hybrid_i_vary_theta = np.zeros(n_param_combinations)\n",
    "looic_hybrid_se_i_vary_theta = np.zeros(n_param_combinations)\n",
    "for i in range(n_param_combinations):\n",
    "    dat_dict_hybrid= {'N':len(dv),         \n",
    "                'response':response_rep[idx,i],\n",
    "                'dv':dv,      \n",
    "                'is_full_energy':is_full_energy ,\n",
    "                'is_low_energy_LC':is_low_energy_LC,\n",
    "                'is_low_energy_HC':is_low_energy_HC,\n",
    "                'is_basic_1':is_basic_1,\n",
    "                'is_basic_2':is_basic_2,\n",
    "                'is_basic_3':is_basic_3,\n",
    "                'is_basic_4':is_basic_4,\n",
    "                'is_23':is_23,\n",
    "                'is_14':is_14\n",
    "                } \n",
    "\n",
    "    res_hybrid = sm_flat_m2.sampling(data=dat_dict_hybrid, iter=2000,  warmup=1000, thin=1, chains=4,control = control_dict,seed=101, verbose = False);\n",
    "    idata_hybrid = az.from_pystan(posterior=res_hybrid,log_likelihood='log_lik')\n",
    "    looic_hybrid = az.loo(idata_hybrid,pointwise=True,scale='deviance')\n",
    "    looic_hybrid_i_vary_theta[i]=looic_hybrid[0]\n",
    "    looic_hybrid_se_i_vary_theta[i]=looic_hybrid[1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    }
   ],
   "source": [
    "control_dict = dict(adapt_delta=0.95)\n",
    "idx = (dat['timeout'] == 0)\n",
    "is_full_energy = dat.loc[idx,['is_full_energy']].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_LC = dat.loc[idx,['is_low_energy_LC']].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_HC = dat.loc[idx,['is_low_energy_HC']].to_numpy(dtype='int').squeeze()\n",
    "is_basic = dat.loc[idx,['is_basic']].to_numpy(dtype='int').squeeze()\n",
    "dv = dat.loc[idx,['dv_simple']].to_numpy().squeeze()\n",
    "\n",
    "looic_simple_i_vary_theta = np.zeros(n_param_combinations)\n",
    "looic_simple_se_i_vary_theta = np.zeros(n_param_combinations)\n",
    "for i in range(n_param_combinations):\n",
    "    dat_dict_simple = {'N':len(dv),         \n",
    "                'response':response_rep[idx,i],\n",
    "                'is_full_energy':is_full_energy ,\n",
    "                'is_low_energy_LC':is_low_energy_LC,\n",
    "                'is_low_energy_HC':is_low_energy_HC,\n",
    "                'is_basic_1':is_basic_1,\n",
    "                'is_basic_2':is_basic_2,\n",
    "                'is_basic_3':is_basic_3,\n",
    "                'is_basic_4':is_basic_4\n",
    "                } \n",
    "\n",
    "\n",
    "    res_simple = sm_flat_m3.sampling(data=dat_dict_simple, iter=2000,  warmup=1000, thin=1, chains=4,seed=101, verbose = False);\n",
    "    idata_simple = az.from_pystan(posterior=res_simple,log_likelihood='log_lik')\n",
    "    looic_simple = az.loo(idata_simple,pointwise=True,scale='deviance')\n",
    "    looic_simple_i_vary_theta[i]=looic_simple[0]\n",
    "    looic_simple_se_i_vary_theta[i]=looic_simple[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vary planning weights $\\beta_{plan}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate novel responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Simulate novel data for refitting \n",
    "is_full_energy_rep = dat['is_full_energy'].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_LC_rep = dat['is_low_energy_LC'].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_HC_rep = dat['is_low_energy_HC'].to_numpy(dtype='int').squeeze()\n",
    "is_basic_1_rep = dat['is_basic_1'].to_numpy(dtype='int').squeeze()\n",
    "is_basic_2_rep = dat['is_basic_2'].to_numpy(dtype='int').squeeze()\n",
    "is_basic_3_rep = dat['is_basic_3'].to_numpy(dtype='int').squeeze()\n",
    "is_basic_4_rep = dat['is_basic_4'].to_numpy(dtype='int').squeeze()\n",
    "is_basic_rep = dat['is_basic'].to_numpy(dtype='int').squeeze()\n",
    "is_23_rep = dat['is_23'].to_numpy(dtype='int').squeeze()\n",
    "is_14_rep = dat['is_14'].to_numpy(dtype='int').squeeze()\n",
    "dv_rep = dat['dv_planning'].to_numpy().squeeze()\n",
    "\n",
    "# Get posterior mean of group and individual paramters \n",
    "beta_dv_23_rep = np.arange(0,6)\n",
    "beta_dv_14_rep = np.arange(0,6)\n",
    "theta_basic_1_rep = summary_hybrid['mu_theta_basic_1']['mean'].to_numpy()\n",
    "theta_basic_2_rep = summary_hybrid['mu_theta_basic_2']['mean'].to_numpy()\n",
    "theta_basic_3_rep = summary_hybrid['mu_theta_basic_3']['mean'].to_numpy()\n",
    "theta_basic_4_rep = summary_hybrid['mu_theta_basic_4']['mean'].to_numpy()\n",
    "theta_full_energy_rep = summary_hybrid['theta_full_energy']['mean'].to_numpy()\n",
    "theta_low_energy_HC_rep = summary_hybrid['theta_low_energy_HC']['mean'].to_numpy()\n",
    "theta_low_energy_LC_rep = summary_hybrid['theta_low_energy_LC']['mean'].to_numpy()\n",
    "\n",
    "# Sample novel binary responses based on posterior mean parameter values\n",
    "n_param_combinations = 6\n",
    "response_rep = np.zeros((len(dat),n_param_combinations))\n",
    "for i in range(n_param_combinations):\n",
    "    logits_rep = theta_full_energy_rep * is_full_energy_rep + theta_low_energy_LC_rep * is_low_energy_LC_rep + theta_low_energy_HC_rep * is_low_energy_HC_rep + theta_basic_1_rep * is_basic_1_rep + theta_basic_2_rep * is_basic_2_rep + theta_basic_3_rep * is_basic_3_rep + theta_basic_4_rep * is_basic_4_rep + beta_dv_23_rep[i] * dv_rep * is_23_rep + beta_dv_14_rep[i] * dv_rep * is_14_rep  \n",
    "    p_rep = sigmoid(logits_rep) \n",
    "    response_rep[:,i] = stats.bernoulli.rvs(p_rep)\n",
    "response_rep = np.array(response_rep,dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the data and sampling posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    }
   ],
   "source": [
    "control_dict = dict(adapt_delta=0.95)\n",
    "idx = (dat['timeout'] == 0)\n",
    "is_full_energy = dat.loc[idx,['is_full_energy']].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_LC = dat.loc[idx,['is_low_energy_LC']].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_HC = dat.loc[idx,['is_low_energy_HC']].to_numpy(dtype='int').squeeze()\n",
    "is_basic = dat.loc[idx,['is_basic']].to_numpy(dtype='int').squeeze()\n",
    "dv = dat.loc[idx,['dv_planning']].to_numpy().squeeze()\n",
    "\n",
    "looic_planning_i_vary_beta = np.zeros(n_param_combinations)\n",
    "looic_planning_se_i_vary_beta = np.zeros(n_param_combinations)\n",
    "for i in range(n_param_combinations):\n",
    "    dat_dict_planning = {'N':len(dv),         \n",
    "                'response':response_rep[idx,i],\n",
    "                'dv':dv, \n",
    "                'is_full_energy':is_full_energy ,\n",
    "                'is_low_energy_LC':is_low_energy_LC,\n",
    "                'is_low_energy_HC':is_low_energy_HC,\n",
    "                'is_basic':is_basic\n",
    "                } \n",
    "\n",
    "\n",
    "    res_planning = sm_flat_m1.sampling(data=dat_dict_planning, iter=2000,  warmup=1000, thin=1, chains=4,seed=101, verbose = False);\n",
    "    idata_planning = az.from_pystan(posterior=res_planning,log_likelihood='log_lik')\n",
    "    looic_planning = az.loo(idata_planning,pointwise=True,scale='deviance')\n",
    "    looic_planning_i_vary_beta[i]=looic_planning[0]\n",
    "    looic_planning_se_i_vary_beta[i]=looic_planning[1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    }
   ],
   "source": [
    "control_dict = dict(adapt_delta=0.95)\n",
    "idx = (dat['timeout'] == 0)\n",
    "is_full_energy = dat.loc[idx,['is_full_energy']].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_LC = dat.loc[idx,['is_low_energy_LC']].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_HC = dat.loc[idx,['is_low_energy_HC']].to_numpy(dtype='int').squeeze()\n",
    "is_basic_1 = dat.loc[idx,['is_basic_1']].to_numpy(dtype='int').squeeze()\n",
    "is_basic_2 = dat.loc[idx,['is_basic_2']].to_numpy(dtype='int').squeeze()\n",
    "is_basic_3 = dat.loc[idx,['is_basic_3']].to_numpy(dtype='int').squeeze()\n",
    "is_basic_4 = dat.loc[idx,['is_basic_4']].to_numpy(dtype='int').squeeze()\n",
    "is_basic = dat.loc[idx,['is_basic']].to_numpy(dtype='int').squeeze()\n",
    "is_23 = dat.loc[idx,['is_23']].to_numpy(dtype='int').squeeze()\n",
    "is_14 = dat.loc[idx,['is_14']].to_numpy(dtype='int').squeeze()\n",
    "dv = dat.loc[idx,['dv_planning']].to_numpy().squeeze()\n",
    "\n",
    "looic_hybrid_i_vary_beta = np.zeros(n_param_combinations)\n",
    "looic_hybrid_se_i_vary_beta = np.zeros(n_param_combinations)\n",
    "for i in range(n_param_combinations):\n",
    "    dat_dict_hybrid= {'N':len(dv),         \n",
    "                'response':response_rep[idx,i],\n",
    "                'dv':dv,      \n",
    "                'is_full_energy':is_full_energy ,\n",
    "                'is_low_energy_LC':is_low_energy_LC,\n",
    "                'is_low_energy_HC':is_low_energy_HC,\n",
    "                'is_basic_1':is_basic_1,\n",
    "                'is_basic_2':is_basic_2,\n",
    "                'is_basic_3':is_basic_3,\n",
    "                'is_basic_4':is_basic_4,\n",
    "                'is_23':is_23,\n",
    "                'is_14':is_14\n",
    "                } \n",
    "\n",
    "    res_hybrid = sm_flat_m2.sampling(data=dat_dict_hybrid, iter=2000,  warmup=1000, thin=1, chains=4,control = control_dict,seed=101, verbose = False);\n",
    "    idata_hybrid = az.from_pystan(posterior=res_hybrid,log_likelihood='log_lik')\n",
    "    looic_hybrid = az.loo(idata_hybrid,pointwise=True,scale='deviance')\n",
    "    looic_hybrid_i_vary_beta[i]=looic_hybrid[0]\n",
    "    looic_hybrid_se_i_vary_beta[i]=looic_hybrid[1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n",
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    }
   ],
   "source": [
    "control_dict = dict(adapt_delta=0.95)\n",
    "idx = (dat['timeout'] == 0)\n",
    "is_full_energy = dat.loc[idx,['is_full_energy']].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_LC = dat.loc[idx,['is_low_energy_LC']].to_numpy(dtype='int').squeeze()\n",
    "is_low_energy_HC = dat.loc[idx,['is_low_energy_HC']].to_numpy(dtype='int').squeeze()\n",
    "is_basic = dat.loc[idx,['is_basic']].to_numpy(dtype='int').squeeze()\n",
    "dv = dat.loc[idx,['dv_simple']].to_numpy().squeeze()\n",
    "\n",
    "looic_simple_i_vary_beta = np.zeros(n_param_combinations)\n",
    "looic_simple_se_i_vary_beta = np.zeros(n_param_combinations)\n",
    "for i in range(n_param_combinations):\n",
    "    dat_dict_simple = {'N':len(dv),         \n",
    "                'response':response_rep[idx,i],\n",
    "                'is_full_energy':is_full_energy ,\n",
    "                'is_low_energy_LC':is_low_energy_LC,\n",
    "                'is_low_energy_HC':is_low_energy_HC,\n",
    "                'is_basic_1':is_basic_1,\n",
    "                'is_basic_2':is_basic_2,\n",
    "                'is_basic_3':is_basic_3,\n",
    "                'is_basic_4':is_basic_4\n",
    "                } \n",
    "\n",
    "\n",
    "    res_simple = sm_flat_m3.sampling(data=dat_dict_simple, iter=2000,  warmup=1000, thin=1, chains=4,seed=101, verbose = False);\n",
    "    idata_simple = az.from_pystan(posterior=res_simple,log_likelihood='log_lik')\n",
    "    looic_simple = az.loo(idata_simple,pointwise=True,scale='deviance')\n",
    "    looic_simple_i_vary_beta[i]=looic_simple[0]\n",
    "    looic_simple_se_i_vary_beta[i]=looic_simple[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot LOOIC for all three models across the range of simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x180 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "barx_simple = np.arange(0,21,4)\n",
    "barx_planning = np.arange(0,21,4)+1\n",
    "barx_hybrid = np.arange(0,21,4)+2\n",
    "xticks = np.arange(0,21,4)+1\n",
    "xticklabels = np.arange(0,6)\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(7,2.5))\n",
    "for i,axes in enumerate(ax.flat):\n",
    "    if i == 0:\n",
    "        axes.bar(barx_simple,looic_simple_i_vary_theta,yerr=looic_simple_se_i_vary_theta,label='SM')\n",
    "        axes.bar(barx_planning,looic_planning_i_vary_theta,yerr=looic_planning_se_i_vary_theta,label='PM')\n",
    "        axes.bar(barx_hybrid,looic_hybrid_i_vary_theta,yerr=looic_hybrid_se_i_vary_theta,label='HM')\n",
    "        axes.set_xlabel(r'|$\\theta_{O i}$|', fontsize=10);\n",
    "        axes.legend(frameon=False)\n",
    "\n",
    "    if i == 1:\n",
    "        axes.bar(barx_simple,looic_simple_i_vary_beta,yerr=looic_simple_se_i_vary_beta)\n",
    "        axes.bar(barx_planning,looic_planning_i_vary_beta,yerr=looic_planning_se_i_vary_beta)\n",
    "        axes.bar(barx_hybrid,looic_hybrid_i_vary_beta,yerr=looic_hybrid_se_i_vary_beta)\n",
    "        axes.set_xlabel(r'$\\beta_{plan}$', fontsize=10);\n",
    "        \n",
    "    axes.set_ylabel('LOOIC')\n",
    "    axes.set_xticks(xticks)\n",
    "    axes.set_xticklabels(xticklabels)\n",
    "\n",
    "#fig.savefig('model_recovery', dpi=300, bbox_inches='tight', transparent=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
